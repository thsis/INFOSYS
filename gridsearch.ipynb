{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Hyperopt` and the Chicago crime data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup for `Google Colab`\n",
    "\n",
    "These scripts are probably going to run for a *good* while - so we want to use possibly better hardware. Thanks to our `Google Overlords` we can play with their toys."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First clone the repo, to give `Google Colab` access to the scripts:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!git clone https://github.com/thsis/INFOSYS.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install required packages in the specified versions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute `preprocessing/crime_preprocessing.py` to generate the files `data/crime_total.csv` and `data/crime_district.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!python3 preprocessing/crime_preprocessing.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.layers import SimpleRNN, LSTM, GRU\n",
    "from models.recurrent import Recurrent\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from hyperopt import tpe, hp, fmin, STATUS_OK, Trials\n",
    "from hyperopt.pyll.base import scope\n",
    "\n",
    "from pprint import pprint\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crime Data\n",
    "\n",
    "This dataset reflects reported incidents of crime (with the exception of murders where data exists for each victim) that occurred in the City of Chicago from 2001 to end of October 2018.\n",
    "\n",
    "Data is extracted from the Chicago Police Department's CLEAR (Citizen Law Enforcement Analysis and Reporting) system. In order to protect the privacy of crime victims, addresses are shown at the block level only and specific locations are not identified.\n",
    "\n",
    "The dataset is readily obtainable under [data.gov](https://catalog.data.gov/dataset/crimes-2001-to-present-398a4).\n",
    "\n",
    "We look at two distinct questions:\n",
    "1. Can we accurately predict the development of the **whole** time series for the city of Chicago?\n",
    "2. Can we accurately predict the development of the series for **each district**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the full series:\n",
    "\n",
    "The full series contains a single column of summed up incidents per day. We also parse the dates inside the `date` column and set them as the index of the `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crimes_total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001-01-01</th>\n",
       "      <td>1814.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-02</th>\n",
       "      <td>1143.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-03</th>\n",
       "      <td>1151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-04</th>\n",
       "      <td>1166.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-05</th>\n",
       "      <td>1267.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            crimes_total\n",
       "date                    \n",
       "2001-01-01        1814.0\n",
       "2001-01-02        1143.0\n",
       "2001-01-03        1151.0\n",
       "2001-01-04        1166.0\n",
       "2001-01-05        1267.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapath_whole = os.path.join(\"data\", \"crime_total.csv\")\n",
    "whole = pd.read_csv(datapath_whole, index_col=[\"date\"],\n",
    "                    dtype={\"crimes_total\": np.float32},\n",
    "                    parse_dates=[\"date\"])\n",
    "whole.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the series by district:\n",
    "\n",
    "Here we also parse the dates inside the `Date` column and specify a `MultiIndex` where the levels are `Date` and then `District`. This allows our `models.recurrent`-class to distinguish between the series for the whole of Chicago and the Chicago crime series by each district."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th colspan=\"21\" halign=\"left\">2001-01-01</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>District</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>3.0</th>\n",
       "      <th>4.0</th>\n",
       "      <th>5.0</th>\n",
       "      <th>6.0</th>\n",
       "      <th>7.0</th>\n",
       "      <th>8.0</th>\n",
       "      <th>9.0</th>\n",
       "      <th>10.0</th>\n",
       "      <th>...</th>\n",
       "      <th>16.0</th>\n",
       "      <th>17.0</th>\n",
       "      <th>18.0</th>\n",
       "      <th>19.0</th>\n",
       "      <th>20.0</th>\n",
       "      <th>21.0</th>\n",
       "      <th>22.0</th>\n",
       "      <th>24.0</th>\n",
       "      <th>25.0</th>\n",
       "      <th>31.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Incidents</th>\n",
       "      <td>37.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>...</td>\n",
       "      <td>67.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Date      2001-01-01                                                      \\\n",
       "District        1.0    2.0    3.0   4.0   5.0   6.0   7.0    8.0    9.0    \n",
       "Incidents       37.0  110.0  103.0  96.0  95.0  84.0  83.0  111.0  109.0   \n",
       "\n",
       "Date             ...                                                         \\\n",
       "District    10.0 ...   16.0  17.0  18.0  19.0  20.0 21.0  22.0  24.0   25.0   \n",
       "Incidents  104.0 ...   67.0  67.0  72.0  72.0  40.0  0.0  61.0  59.0  120.0   \n",
       "\n",
       "Date            \n",
       "District  31.0  \n",
       "Incidents  0.0  \n",
       "\n",
       "[1 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapath_district = os.path.join(\"data\", \"crimes_district.csv\")\n",
    "district = pd.read_csv(datapath_district, index_col=[\"Date\", \"District\"],\n",
    "                       dtype={\"District\": object,\n",
    "                              \"Incidents\": np.float32},\n",
    "                       parse_dates=[\"Date\"])\n",
    "district.sort_index().head(24).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate data and a holdout set.\n",
    "\n",
    "Because we use a library that tunes parameters with regards to the test set, we need to separate a holdout set. On this set, which we will not expose to our models we can evaluate the performance of our tuned models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = pd.to_datetime(\"2018-10-01\")\n",
    "whole_data = whole.loc[whole.index < cutoff]\n",
    "whole_holdout = whole.loc[whole.index >= cutoff]\n",
    "\n",
    "# As always with MultiIndices, things are a little more complicated.\n",
    "district_data = district.loc[district.index.map(lambda x: x[0] < cutoff)]\n",
    "district_holdout = district.loc[district.index.map(lambda x: x[0] > cutoff)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if we did not, by accident, create *views* on the data. We explicitly want *copies*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not whole_data.values.base is whole.values.base\n",
    "assert not district_data.values.base is district.values.base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperopt parameter spaces\n",
    "\n",
    "Most of our models have similar parameters which we want to tune. For the sampling of the subspace we use mostly uniform distributions, since they impose the least a-priori assumptions on where the optimal parameters lie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add optimizer, learn-rate, \n",
    "paramspace = {\"maxlag\": scope.int(hp.quniform(\"maxlag\", 0, 365, 1)),\n",
    "              \"cell_neurons\": scope.int(hp.quniform(\"cell_neurons\", 1, 30, 1)),\n",
    "              \"batch_size\": scope.int(hp.quniform(\"batch_size\", 1, 10, 1))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have defined a base parameter space dictionary which we update with the parameters which are more specific to each cell. This can get out of hand pretty fast, therefore we generate a dictionary through a loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'GRU': {'batch_size': <hyperopt.pyll.base.Apply object at 0x7fbe7dbff160>,\n",
      "         'cell': <class 'keras.layers.recurrent.GRU'>,\n",
      "         'cell_neurons': <hyperopt.pyll.base.Apply object at 0x7fbe7dbff438>,\n",
      "         'maxlag': <hyperopt.pyll.base.Apply object at 0x7fbe7db863c8>},\n",
      " 'LSTM': {'batch_size': <hyperopt.pyll.base.Apply object at 0x7fbe7dbff160>,\n",
      "          'cell': <class 'keras.layers.recurrent.LSTM'>,\n",
      "          'cell_neurons': <hyperopt.pyll.base.Apply object at 0x7fbe7dbff438>,\n",
      "          'maxlag': <hyperopt.pyll.base.Apply object at 0x7fbe7db863c8>},\n",
      " 'SimpleRNN': {'batch_size': <hyperopt.pyll.base.Apply object at 0x7fbe7dbff160>,\n",
      "               'cell': <class 'keras.layers.recurrent.SimpleRNN'>,\n",
      "               'cell_neurons': <hyperopt.pyll.base.Apply object at 0x7fbe7dbff438>,\n",
      "               'maxlag': <hyperopt.pyll.base.Apply object at 0x7fbe7db863c8>}}\n"
     ]
    }
   ],
   "source": [
    "spacesdict ={}\n",
    "for cell in (SimpleRNN, LSTM, GRU):\n",
    "    spacesdict[cell.__name__] = {\"cell\": cell, **paramspace}\n",
    "\n",
    "pprint(spacesdict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to store the results of each `hyperopt`-search we can create a `hyperopt.Trials`-object, which is very similar to a native Python `dictionary`. And because we want to fit *three* models on *two* different datasets and are too lazy to type *six* times virtually the same code we user a dictionary comprehension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'district': {'GRU': <hyperopt.base.Trials object at 0x7fbe7dbff1d0>,\n",
      "              'LSTM': <hyperopt.base.Trials object at 0x7fbe7dbff198>,\n",
      "              'SimpleRNN': <hyperopt.base.Trials object at 0x7fbe7db86400>},\n",
      " 'whole': {'GRU': <hyperopt.base.Trials object at 0x7fbe7db862e8>,\n",
      "           'LSTM': <hyperopt.base.Trials object at 0x7fbe7db86a20>,\n",
      "           'SimpleRNN': <hyperopt.base.Trials object at 0x7fbe7db86320>}}\n"
     ]
    }
   ],
   "source": [
    "trialsdict = {key: {model: Trials() for model in (\"SimpleRNN\", \"LSTM\", \"GRU\")} for key in (\"whole\", \"district\")}\n",
    "pprint(trialsdict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing over the parameter space\n",
    "\n",
    "We could of course write an objective function and a separate call to `hyperopt.fmin` for each of the three model-classes per dataset, which would result in 12 different function calls - this is way too tedious and prone to errors.\n",
    "\n",
    "That's why we will use the `Python`-decorator syntax. We first define a second order function that contains the part of `hyperopt` that minimizes objective functions and which will in turn expect a function as its only argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimizer(objective):\n",
    "    def outer(paramspace, trials, max_evals=3):\n",
    "        def inner(*args, **kwargs):\n",
    "            return objective(*args, **kwargs)\n",
    "        \n",
    "        best = fmin(fn=inner,\n",
    "                    space=paramspace,\n",
    "                    algo=tpe.suggest,\n",
    "                    max_evals=max_evals,\n",
    "                    trials=trials)\n",
    "        return best\n",
    "    return outer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now to the function we wish to decorate. It contains 3 steps:\n",
    "1. Create a model with a certain set of (yet undefined) parameters.\n",
    "2. Train the model.\n",
    "3. Calculate the loss on a test set and return a dictionary, that contains the loss and a flag indicating that everything went okay.\n",
    "\n",
    "We do this for the whole series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@minimizer\n",
    "def whole_get_loss(params):\n",
    "    \"\"\"Return loss on test set.\"\"\"\n",
    "    model = Recurrent(whole_data, epochs=3, verbose=False, **params)\n",
    "    model.train()\n",
    "    predictions = model.forecast(model.X_test)\n",
    "    loss = mean_squared_error(y_true=model.y_test, y_pred=predictions)\n",
    "    return {'loss': loss, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And for the series by district:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@minimizer\n",
    "def district_get_loss(params):\n",
    "    \"\"\"Return loss on test set.\"\"\"\n",
    "    model = Recurrent(district_data, epochs=3, verbose=False, **params)\n",
    "    model.train()\n",
    "    predictions = model.forecast(model.X_test)\n",
    "    loss = mean_squared_error(y_true=model.y_test, y_pred=predictions)\n",
    "    return {'loss': loss, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now to tuning the hyperparameters. Again we pass through all our models for each dataset and store the best hyperparameters in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = (\"SimpleRNN\", \"LSTM\", \"GRU\")\n",
    "best_whole = {}\n",
    "best_district = {}\n",
    "for model in models:\n",
    "    best_whole[model] = whole_get_loss(spacesdict[model], \n",
    "                                       trialsdict[\"whole\"][model])\n",
    "    best_district[model] = district_get_loss(spacesdict[model],\n",
    "                                             trialsdict[\"district\"][model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'GRU': {'batch_size': 5.0, 'cell_neurons': 23.0, 'maxlag': 251.0},\n",
      " 'LSTM': {'batch_size': 3.0, 'cell_neurons': 13.0, 'maxlag': 363.0},\n",
      " 'SimpleRNN': {'batch_size': 6.0, 'cell_neurons': 13.0, 'maxlag': 284.0}}\n"
     ]
    }
   ],
   "source": [
    "pprint(best_whole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'GRU': {'batch_size': 4.0, 'cell_neurons': 22.0, 'maxlag': 359.0},\n",
      " 'LSTM': {'batch_size': 5.0, 'cell_neurons': 10.0, 'maxlag': 352.0},\n",
      " 'SimpleRNN': {'batch_size': 4.0, 'cell_neurons': 23.0, 'maxlag': 242.0}}\n"
     ]
    }
   ],
   "source": [
    "pprint(best_district)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason why we use dictionaries so much is, because we can easily save them as a `json`-file which then in turn can be exported to other programming languages as well (which is much harder if you save your objects as with the `pickle` module)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('best_whole.json', 'w') as outfile:\n",
    "    json.dump(best_whole, outfile)\n",
    "\n",
    "with open('best_district.json', 'w') as outfile:\n",
    "    json.dump(best_district, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the search Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_trials(trials, paramspace, savepath=None):\n",
    "    \"\"\"Plot path of hyperopt-search for analysis.\"\"\"\n",
    "    parameters = [k for k in paramspace.keys() if k != \"cell\"]\n",
    "    cols = len(parameters)\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=cols, figsize=(20, 5))\n",
    "\n",
    "    for i, val in enumerate(parameters):\n",
    "        xs = np.array([t['misc']['vals'][val] for t in trials.trials]).ravel()\n",
    "        ys = [t['result']['loss'] for t in trials.trials]\n",
    "        xs, ys = zip(*sorted(zip(xs, ys)))\n",
    "        axes[i].scatter(xs, ys, s=20, linewidth=0.01, alpha=0.25)\n",
    "        axes[i].set_title(val)\n",
    "        axes[i].set_ylim([0, 0.002])\n",
    "        \n",
    "    fig.suptitle(\"Hyperopt-path for {}\".format(paramspace[\"cell\"].__name__))\n",
    "    if savepath:\n",
    "        fig.savefig(savepath)\n",
    "\n",
    "    return fig, axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_gru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_trials(paramspace=space4lstm, trials=lstm_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix type of optimal parameters\n",
    "best = {key: int(val) for key, val in best.items()}\n",
    "fig, axes = plot_trials(trials=trials, paramspace=paramspace)\n",
    "plt.savefig(os.path.join(\"models\", \"lstm-district-hyperopt-search.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59049"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3**10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
